{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "- DataFrame API docs: https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame\n",
    "\n",
    "Rules of thumb:\n",
    "- Hit tab to auto-complete\n",
    "- To see all available methods, place a dot (.) after the RDD (e.g. words.) and hit tab \n",
    "- Use `.collect()` to see the contents of the RDD\n",
    "\n",
    "Solutions for potentially challenging exercises can be found in the end of the section. Don't peek unless you're really stuck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://duns-mbp:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x112d69f60>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# like in the pyspark shell, SparkSession is already defined\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DataFrame methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(AGE=36, gender='female', height=180, name='Zoe')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.json(\"../data/people/names.json\")\n",
    "df.head()\n",
    "# other supported file formats:\n",
    "# spark.read.parquet(\"../data/pems_sorted/\")\n",
    "# spark.read.text()\n",
    "# spark.read.csv()\n",
    "# spark.read.orc()\n",
    "\n",
    "# generic form: \n",
    "# spark.read.load(\"path/to/someFile.csv\", format=\"csv\", sep=\":\", inferSchema=\"true\", header=\"true\")\n",
    "\n",
    "# Loading data from a JDBC source\n",
    "# jdbcDF = spark.read \\\n",
    "#     .format(\"jdbc\") \\\n",
    "#     .option(\"url\", \"jdbc:postgresql:dbserver\") \\\n",
    "#     .option(\"dbtable\", \"schema.tablename\") \\\n",
    "#     .option(\"user\", \"username\") \\\n",
    "#     .option(\"password\", \"password\") \\\n",
    "#     .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(value='Basics of the Unix Philosophy')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: write reading different files in ../data\n",
    "word_df = spark.read.text(\"../data/word_count\")\n",
    "word_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(timeperiod='09/04/2016 00:00:19', flow1=5, occupancy1=0.025, speed1=78.0, flow2=7, occupancy2=0.0311, speed2=71.0, flow3=1, occupancy3=0.4706, speed3=1.0, flow4=None, occupancy4=None, speed4=None, flow5=None, occupancy5=None, speed5=None, flow6=None, occupancy6=None, speed6=None, flow7=None, occupancy7=None, speed7=None, flow8=None, occupancy8=None, speed8=None, station=402260),\n",
       " Row(timeperiod='09/04/2016 00:00:49', flow1=0, occupancy1=0.0, speed1=0.0, flow2=0, occupancy2=0.0, speed2=0.0, flow3=0, occupancy3=0.0, speed3=0.0, flow4=None, occupancy4=None, speed4=None, flow5=None, occupancy5=None, speed5=None, flow6=None, occupancy6=None, speed6=None, flow7=None, occupancy7=None, speed7=None, flow8=None, occupancy8=None, speed8=None, station=402260)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.parquet(\"../data/pems_sorted/\").head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0='Time', _c1='V1', _c2='V2', _c3='V3', _c4='V4', _c5='V5', _c6='V6', _c7='V7', _c8='V8', _c9='V9', _c10='V10', _c11='V11', _c12='V12', _c13='V13', _c14='V14', _c15='V15', _c16='V16', _c17='V17', _c18='V18', _c19='V19', _c20='V20', _c21='V21', _c22='V22', _c23='V23', _c24='V24', _c25='V25', _c26='V26', _c27='V27', _c28='V28', _c29='Amount', _c30='Class'),\n",
       " Row(_c0='0', _c1='-1.3598071336738', _c2='-0.0727811733098497', _c3='2.53634673796914', _c4='1.37815522427443', _c5='-0.338320769942518', _c6='0.462387777762292', _c7='0.239598554061257', _c8='0.0986979012610507', _c9='0.363786969611213', _c10='0.0907941719789316', _c11='-0.551599533260813', _c12='-0.617800855762348', _c13='-0.991389847235408', _c14='-0.311169353699879', _c15='1.46817697209427', _c16='-0.470400525259478', _c17='0.207971241929242', _c18='0.0257905801985591', _c19='0.403992960255733', _c20='0.251412098239705', _c21='-0.018306777944153', _c22='0.277837575558899', _c23='-0.110473910188767', _c24='0.0669280749146731', _c25='0.128539358273528', _c26='-0.189114843888824', _c27='0.133558376740387', _c28='-0.0210530534538215', _c29='149.62', _c30='0')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.csv(\"../data/credit_card\").head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data output (writing to disk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- API docs: https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrameWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing to a file\n",
    "df.write.parquet(\"new_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwrite on save\n",
    "df.write.mode(\"overwrite\").parquet(\"new_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can read from any format and write to any format (barring formatting limitations/rules):\n",
    "# df.write.csv(\"new_data.csv\",header=True)\n",
    "# df.write.json(\"new_data.json\")\n",
    "# df.write.orc(\"new_data.orc\")\n",
    "# df.write.parquet(\"new_data.parquet\")\n",
    "\n",
    "# generic form:\n",
    "# df.write.save(\"fileName.parquet\", format=\"parquet\")\n",
    "# df.write.mode(\"overwrite\").save(\"fileName.parquet\", format=\"parquet\")\n",
    "\n",
    "# Saving data to a JDBC source\n",
    "# jdbcDF.write \\\n",
    "#     .format(\"jdbc\") \\\n",
    "#     .option(\"url\", \"jdbc:postgresql:dbserver\") \\\n",
    "#     .option(\"dbtable\", \"schema.tablename\") \\\n",
    "#     .option(\"user\", \"username\") \\\n",
    "#     .option(\"password\", \"password\") \\\n",
    "#     .save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(\"../data/people/names.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(AGE=36, gender='female', height=180, name='Zoe'),\n",
       " Row(AGE=23, gender='female', height=165, name='Alice'),\n",
       " Row(AGE=30, gender='male', height=175, name='Andy'),\n",
       " Row(AGE=25, gender='female', height=170, name='Jane'),\n",
       " Row(AGE=None, gender='male', height=165, name='Michael')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+------+-------+\n",
      "| AGE|gender|height|   name|\n",
      "+----+------+------+-------+\n",
      "|  36|female|   180|    Zoe|\n",
      "|  23|female|   165|  Alice|\n",
      "|  30|  male|   175|   Andy|\n",
      "|  25|female|   170|   Jane|\n",
      "|null|  male|   165|Michael|\n",
      "+----+------+------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(AGE=36, gender='female', height=180, name='Zoe'),\n",
       " Row(AGE=23, gender='female', height=165, name='Alice'),\n",
       " Row(AGE=30, gender='male', height=175, name='Andy'),\n",
       " Row(AGE=25, gender='female', height=170, name='Jane'),\n",
       " Row(AGE=None, gender='male', height=165, name='Michael')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+-----+\n",
      "|AGE|gender|height| name|\n",
      "+---+------+------+-----+\n",
      "| 36|female|   180|  Zoe|\n",
      "| 23|female|   165|Alice|\n",
      "| 30|  male|   175| Andy|\n",
      "+---+------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# limit(n) returns a new dataframe with the first n rows of the dataframe\n",
    "df.limit(3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+------+-------+\n",
      "| AGE|gender|height|   name|\n",
      "+----+------+------+-------+\n",
      "|  36|female|   180|    Zoe|\n",
      "|  23|female|   165|  Alice|\n",
      "|  30|  male|   175|   Andy|\n",
      "|  25|female|   170|   Jane|\n",
      "|null|  male|   165|Michael|\n",
      "|  19|  male|   180| Justin|\n",
      "+----+------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- AGE: long (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- height: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AGE', 'gender', 'height', 'name']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------+-----------------+-----+\n",
      "|summary|              AGE|gender|           height| name|\n",
      "+-------+-----------------+------+-----------------+-----+\n",
      "|  count|                5|     6|                6|    6|\n",
      "|   mean|             26.6|  null|            172.5| null|\n",
      "| stddev|6.580273550544841|  null|6.892024376045112| null|\n",
      "|    min|               19|female|              165|Alice|\n",
      "|    max|               36|  male|              180|  Zoe|\n",
      "+-------+-----------------+------+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting specific columns in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'name'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting a column\n",
    "# Column API docs: http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.Column\n",
    "df['name']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(name='Zoe')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a new dataframe with only selected columns\n",
    "df.select('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+\n",
      "|   name| age|\n",
      "+-------+----+\n",
      "|    Zoe|  36|\n",
      "|  Alice|  23|\n",
      "|   Andy|  30|\n",
      "|   Jane|  25|\n",
      "|Michael|null|\n",
      "| Justin|  19|\n",
      "+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# creating a new dataframe with only selected columns\n",
    "df.select(['name', 'age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming columns\n",
    "df = df.withColumnRenamed('AGE', 'age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: bigint, gender: string, height: bigint, name: string]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+------+-------+---------------+\n",
      "| age|gender|height|   name|height plus 100|\n",
      "+----+------+------+-------+---------------+\n",
      "|  36|female|   180|    Zoe|            280|\n",
      "|  23|female|   165|  Alice|            265|\n",
      "|  30|  male|   175|   Andy|            275|\n",
      "|  25|female|   170|   Jane|            270|\n",
      "|null|  male|   165|Michael|            265|\n",
      "|  19|  male|   180| Justin|            280|\n",
      "+----+------+------+-------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating new columns\n",
    "df = df.withColumn('height plus 100', df.height + 100)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+------+-------+---------------+-------+\n",
      "| age|gender|height|   name|height plus 100|is_tall|\n",
      "+----+------+------+-------+---------------+-------+\n",
      "|  36|female|   180|    Zoe|            280|   true|\n",
      "|  23|female|   165|  Alice|            265|  false|\n",
      "|  30|  male|   175|   Andy|            275|   true|\n",
      "|  25|female|   170|   Jane|            270|  false|\n",
      "|null|  male|   165|Michael|            265|  false|\n",
      "|  19|  male|   180| Justin|            280|   true|\n",
      "+----+------+------+-------+---------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating new columns\n",
    "df = df.withColumn('is_tall', df.height >= 175)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering\n",
    "`.filter()` takes in either (i) a `Column` of `types.BooleanType` or (ii) a string of SQL expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----+---------------+-------+\n",
      "|age|gender|height|name|height plus 100|is_tall|\n",
      "+---+------+------+----+---------------+-------+\n",
      "| 36|female|   180| Zoe|            280|   true|\n",
      "| 30|  male|   175|Andy|            275|   true|\n",
      "| 25|female|   170|Jane|            270|  false|\n",
      "+---+------+------+----+---------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter using SQL expressions\n",
    "# df.where('age >= 25').show() is also possible because .where() is an alias for .filter()\n",
    "df.filter('age >= 25').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----+---------------+-------+\n",
      "|age|gender|height|name|height plus 100|is_tall|\n",
      "+---+------+------+----+---------------+-------+\n",
      "| 36|female|   180| Zoe|            280|   true|\n",
      "| 30|  male|   175|Andy|            275|   true|\n",
      "| 25|female|   170|Jane|            270|  false|\n",
      "+---+------+------+----+---------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter using a column of boolean types\n",
    "df.filter(df.age >= 25).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'(age >= 25)'>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.age >= 25 returns a Column of booleans\n",
    "df.age >= 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----+---------------+-------+\n",
      "|age|gender|height|name|height plus 100|is_tall|\n",
      "+---+------+------+----+---------------+-------+\n",
      "| 30|  male|   175|Andy|            275|   true|\n",
      "| 25|female|   170|Jane|            270|  false|\n",
      "+---+------+------+----+---------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter( (df.age >= 25) & (df.age <= 30) ).show()\n",
    "# you can use df.age or df['age']\n",
    "# you can replace & with | for 'or' operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+-----+---------------+-------+\n",
      "|age|gender|height| name|height plus 100|is_tall|\n",
      "+---+------+------+-----+---------------+-------+\n",
      "| 36|female|   180|  Zoe|            280|   true|\n",
      "| 23|female|   165|Alice|            265|  false|\n",
      "| 25|female|   170| Jane|            270|  false|\n",
      "+---+------+------+-----+---------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: try filtering based on other predicates\n",
    "df.filter(df.gender == \"female\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+------+---------------+-------+\n",
      "|age|gender|height|  name|height plus 100|is_tall|\n",
      "+---+------+------+------+---------------+-------+\n",
      "| 36|female|   180|   Zoe|            280|   true|\n",
      "| 30|  male|   175|  Andy|            275|   true|\n",
      "| 19|  male|   180|Justin|            280|   true|\n",
      "+---+------+------+------+---------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.is_tall).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+-----+---------------+-------+\n",
      "|age|gender|height| name|height plus 100|is_tall|\n",
      "+---+------+------+-----+---------------+-------+\n",
      "| 23|female|   165|Alice|            265|  false|\n",
      "| 30|  male|   175| Andy|            275|   true|\n",
      "+---+------+------+-----+---------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.name.startswith(\"A\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### groupBy\n",
    "\n",
    "TL;DR - `.groupBy()` allows you to group rows together based on its value in some given column(s)\n",
    "- `df.groupBy([cols])`\n",
    "- [GroupedData operations](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.GroupedData) (alternatively, you can instantiate a variable with the type of GroupedData, let jupyter notebook's intellisense show you what methods are available:\n",
    "    - `grouped = df.groupBy('gender')`\n",
    "    - `grouped.` (and hit tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(age=36, gender='female', height=180, name='Zoe', height plus 100=280, is_tall=True)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.group.GroupedData at 0x1133c80f0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy('gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupBy('gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|gender|count|\n",
      "+------+-----+\n",
      "|female|    3|\n",
      "|  male|    3|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('gender').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------------------+--------------------+\n",
      "|gender|avg(age)|       avg(height)|avg(height plus 100)|\n",
      "+------+--------+------------------+--------------------+\n",
      "|female|    28.0|171.66666666666666|   271.6666666666667|\n",
      "|  male|    24.5|173.33333333333334|   273.3333333333333|\n",
      "+------+--------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('gender').avg().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+--------------------+\n",
      "|sum(age)|sum(height)|sum(height plus 100)|\n",
      "+--------+-----------+--------------------+\n",
      "|     133|       1035|                1635|\n",
      "+--------+-----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculating total age and height of all people (i.e. don't groupby anything)\n",
    "df.groupBy().sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|avg(height)|\n",
      "+-----------+\n",
      "|      172.5|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: calculate average height of all people \n",
    "df.select('height').groupBy().avg().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+\n",
      "|gender|max(height)|\n",
      "+------+-----------+\n",
      "|female|        180|\n",
      "|  male|        180|\n",
      "+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: calculate max height for each gender\n",
    "df.select(['gender', 'height']).groupBy('gender').max().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+\n",
      "|gender|min(height)|\n",
      "+------+-----------+\n",
      "|female|        165|\n",
      "|  male|        165|\n",
      "+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: calculate min height for each gender\n",
    "df.select(['gender', 'height']).groupBy('gender').min().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Crimes Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+-----+--------------------+----------------------+---------------------+------+--------+----+----+------+------------+------------+------------+-------------+--------------------+\n",
      "|   CASE#| DATE  OF OCCURRENCE|               BLOCK| IUCR| PRIMARY DESCRIPTION| SECONDARY DESCRIPTION| LOCATION DESCRIPTION|ARREST|DOMESTIC|BEAT|WARD|FBI CD|X COORDINATE|Y COORDINATE|    LATITUDE|    LONGITUDE|            LOCATION|\n",
      "+--------+--------------------+--------------------+-----+--------------------+----------------------+---------------------+------+--------+----+----+------+------------+------------+------------+-------------+--------------------+\n",
      "|JB241987|04/28/2018 10:05:...|    009XX N LONG AVE| 2092|           NARCOTICS|  SOLICIT NARCOTICS...|             SIDEWALK|     Y|       N|1524|  37|    18|     1140136|     1905903|41.897894893|-87.760743714|(41.897894893, -8...|\n",
      "|JA430240|09/06/2017 01:30:...|     032XX W 26TH ST| 0810|               THEFT|             OVER $500|                OTHER|     Y|       N|1024|  12|    06|     1155313|     1886555|41.844510467|-87.705519454|(41.844510467, -8...|\n",
      "|JB241350|04/28/2018 08:00:...|     008XX E 53RD ST| 1320|     CRIMINAL DAMAGE|            TO VEHICLE|               STREET|     N|       N| 233|   5|    14|     1182892|     1870055|41.798635468|-87.604823241|(41.798635468, -8...|\n",
      "|JB245397|04/28/2018 09:00:...|062XX S MICHIGAN AVE| 0820|               THEFT|        $500 AND UNDER| RESIDENCE PORCH/H...|     N|       N| 311|  20|    06|     1178263|     1863570|41.780946398|-87.621995369|(41.780946398, -8...|\n",
      "|JB241444|04/28/2018 12:15:...|  046XX N ELSTON AVE| 0890|               THEFT|         FROM BUILDING|   SMALL RETAIL STORE|     N|       N|1722|  39|    06|     1146646|     1930549|41.965404069|-87.736202402|(41.965404069, -8...|\n",
      "|JB241667|04/28/2018 04:28:...| 022XX S KENNETH AVE| 1020|               ARSON|               BY FIRE| VEHICLE NON-COMME...|     N|       N|1013|  22|    09|     1147102|     1888742|41.850672642|-87.735596947|(41.850672642, -8...|\n",
      "|JA476742|10/18/2017 11:55:...|  006XX N CICERO AVE| 0910| MOTOR VEHICLE THEFT|            AUTOMOBILE|               STREET|     N|       N|1532|  28|    07|     1144251|     1903638|41.891603117|-87.745686519|(41.891603117, -8...|\n",
      "|JA509627|11/13/2017 02:35:...|025XX W WELLINGTO...| 0326|             ROBBERY|  AGGRAVATED VEHICU...|               STREET|     N|       N|1411|   1|    03|     1158944|     1919849|41.935798543|-87.691279962|(41.935798543, -8...|\n",
      "|JB241316|04/28/2018 11:15:...| 007XX N DEARBORN ST| 0460|             BATTERY|                SIMPLE|           RESTAURANT|     Y|       N|1832|  42|   08B|     1175802|     1905458|41.895945884|-87.629759893|(41.895945884, -8...|\n",
      "|JB241116|04/28/2018 08:50:...|013XX S CALIFORNI...| 0312|             ROBBERY|  ARMED:KNIFE/CUTTI...|                ALLEY|     N|       N|1023|  28|    03|     1157906|     1893450|41.863378684| -87.69581565|(41.863378684, -8...|\n",
      "|JB241656|04/28/2018 02:30:...|012XX S LAKE SHOR...| 0890|               THEFT|         FROM BUILDING|                OTHER|     N|       N| 132|   2|    06|     1178818|     1894964|41.867081407|-87.619003708|(41.867081407, -8...|\n",
      "|JB241546|04/28/2018 02:57:...|056XX S DORCHESTE...| 2820|       OTHER OFFENSE|      TELEPHONE THREAT|            RESIDENCE|     N|       N| 235|   5|    26|     1186509|     1867951|41.792777048|  -87.5916257|(41.792777048, -8...|\n",
      "|JB243959|04/28/2018 08:00:...| 068XX S ASHLAND AVE| 0890|               THEFT|         FROM BUILDING|   SMALL RETAIL STORE|     N|       N| 725|  17|    06|     1166850|     1859459|41.769916749|-87.663954978|(41.769916749, -8...|\n",
      "|JA502131|11/07/2017 08:22:...|    055XX N BROADWAY| 0630|            BURGLARY|  ATTEMPT FORCIBLE ...| PARKING LOT/GARAG...|     N|       N|2023|  48|    05|     1167310|     1936985|41.982644337|-87.660039566|(41.982644337, -8...|\n",
      "|JB240951|04/28/2018 12:55:...|045XX S MARSHFIEL...| 0486|             BATTERY|  DOMESTIC BATTERY ...|            APARTMENT|     N|       Y| 924|   3|   08B|     1166099|     1874557|41.811363517|-87.666278426|(41.811363517, -8...|\n",
      "|JB212522|04/04/2018 11:55:...|063XX S CHAMPLAIN...| 1710|OFFENSE INVOLVING...|  ENDANGERING LIFE/...|            APARTMENT|     Y|       Y| 312|  20|    20|     1181657|     1863154|41.779727136|-87.609565241|(41.779727136, -8...|\n",
      "|JB241046|04/28/2018 04:00:...|    0000X E 120TH ST| 0460|             BATTERY|                SIMPLE|               STREET|     Y|       N| 532|   9|   08B|     1178654|     1825407|41.676213432| -87.62171858|(41.676213432, -8...|\n",
      "|JB241479|04/28/2018 01:59:...| 057XX S ABERDEEN ST| 4387|       OTHER OFFENSE|  VIOLATE ORDER OF ...|                OTHER|     N|       Y| 712|  16|    26|     1169962|     1866746|41.789846121|-87.652336186|(41.789846121, -8...|\n",
      "|JB243515|04/28/2018 09:00:...|088XX S COTTAGE G...| 0820|               THEFT|        $500 AND UNDER| VEHICLE NON-COMME...|     N|       N| 632|   6|    06|     1183113|     1846339|41.733551299|-87.604749489|(41.733551299, -8...|\n",
      "|JB241359|04/28/2018 12:45:...|   027XX N MOODY AVE| 0486|             BATTERY|  DOMESTIC BATTERY ...|            RESIDENCE|     N|       Y|2512|  29|   08B|     1134936|     1917499|41.929809369|-87.779568121|(41.929809369, -8...|\n",
      "+--------+--------------------+--------------------+-----+--------------------+----------------------+---------------------+------+--------+----+----+------+------------+------------+------------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crimes = spark.read.csv(\"../data/crimes/Crimes_-_One_year_prior_to_present.csv\", header=True, inferSchema=True)\n",
    "crimes.show()\n",
    "# try the above without the header and inferSchema option. see what happens!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CASE#: string (nullable = true)\n",
      " |-- DATE  OF OCCURRENCE: string (nullable = true)\n",
      " |-- BLOCK: string (nullable = true)\n",
      " |--  IUCR: string (nullable = true)\n",
      " |--  PRIMARY DESCRIPTION: string (nullable = true)\n",
      " |--  SECONDARY DESCRIPTION: string (nullable = true)\n",
      " |--  LOCATION DESCRIPTION: string (nullable = true)\n",
      " |-- ARREST: string (nullable = true)\n",
      " |-- DOMESTIC: string (nullable = true)\n",
      " |-- BEAT: integer (nullable = true)\n",
      " |-- WARD: integer (nullable = true)\n",
      " |-- FBI CD: string (nullable = true)\n",
      " |-- X COORDINATE: integer (nullable = true)\n",
      " |-- Y COORDINATE: integer (nullable = true)\n",
      " |-- LATITUDE: double (nullable = true)\n",
      " |-- LONGITUDE: double (nullable = true)\n",
      " |-- LOCATION: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: print the schema of the dataframe (e.g. data type of each column)?\n",
    "crimes.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263191"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: how many rows are there in the dataframe?\n",
    "crimes.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+----------------+-----+--------------------+----------------------+---------------------+------+--------+----+----+------+------------+------------+------------+-------------+--------------------+\n",
      "|   CASE#| DATE  OF OCCURRENCE|           BLOCK| IUCR| PRIMARY DESCRIPTION| SECONDARY DESCRIPTION| LOCATION DESCRIPTION|ARREST|DOMESTIC|BEAT|WARD|FBI CD|X COORDINATE|Y COORDINATE|    LATITUDE|    LONGITUDE|            LOCATION|\n",
      "+--------+--------------------+----------------+-----+--------------------+----------------------+---------------------+------+--------+----+----+------+------------+------------+------------+-------------+--------------------+\n",
      "|JB241987|04/28/2018 10:05:...|009XX N LONG AVE| 2092|           NARCOTICS|  SOLICIT NARCOTICS...|             SIDEWALK|     Y|       N|1524|  37|    18|     1140136|     1905903|41.897894893|-87.760743714|(41.897894893, -8...|\n",
      "|JA430240|09/06/2017 01:30:...| 032XX W 26TH ST| 0810|               THEFT|             OVER $500|                OTHER|     Y|       N|1024|  12|    06|     1155313|     1886555|41.844510467|-87.705519454|(41.844510467, -8...|\n",
      "+--------+--------------------+----------------+-----+--------------------+----------------------+---------------------+------+--------+----+----+------+------------+------------+------------+-------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Display the first 2 rows\n",
    "crimes.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CASE#',\n",
       " 'DATE  OF OCCURRENCE',\n",
       " 'BLOCK',\n",
       " ' IUCR',\n",
       " ' PRIMARY DESCRIPTION',\n",
       " ' SECONDARY DESCRIPTION',\n",
       " ' LOCATION DESCRIPTION',\n",
       " 'ARREST',\n",
       " 'DOMESTIC',\n",
       " 'BEAT',\n",
       " 'WARD',\n",
       " 'FBI CD',\n",
       " 'X COORDINATE',\n",
       " 'Y COORDINATE',\n",
       " 'LATITUDE',\n",
       " 'LONGITUDE',\n",
       " 'LOCATION']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: What columns are in the dataframe?\n",
    "crimes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CASE#',\n",
       " 'DATE  OF OCCURRENCE',\n",
       " 'BLOCK',\n",
       " 'IUCR',\n",
       " 'PRIMARY DESCRIPTION',\n",
       " 'SECONDARY DESCRIPTION',\n",
       " 'LOCATION DESCRIPTION',\n",
       " 'ARREST',\n",
       " 'DOMESTIC',\n",
       " 'BEAT',\n",
       " 'WARD',\n",
       " 'FBI CD',\n",
       " 'X COORDINATE',\n",
       " 'Y COORDINATE',\n",
       " 'LATITUDE',\n",
       " 'LONGITUDE',\n",
       " 'LOCATION']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's rename the improperly formatted column names\n",
    "columnNames = crimes.columns\n",
    "for col in columnNames:\n",
    "    crimes = crimes.withColumnRenamed(col, col.strip())\n",
    "    \n",
    "crimes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|ARREST| count|\n",
      "+------+------+\n",
      "|     Y| 50126|\n",
      "|     N|213065|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: How many cases resulted in arrest, and how many didn’t?\n",
    "# Hint: Highlight whitespace between this cell and the next cell to see the hint\n",
    "crimes.groupBy('ARREST').count().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"white\">Use .groupBy(\"ARREST\")</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|WARD|count|\n",
      "+----+-----+\n",
      "|  31| 3258|\n",
      "|  34| 6845|\n",
      "|  28|11071|\n",
      "|  27|10000|\n",
      "|  26| 3498|\n",
      "|  44| 3968|\n",
      "|  12| 3036|\n",
      "|  22| 3014|\n",
      "|  47| 2708|\n",
      "|   1| 4873|\n",
      "|  13| 3086|\n",
      "|  16| 6234|\n",
      "|   6| 8427|\n",
      "|   3| 6860|\n",
      "|  20| 7608|\n",
      "|  40| 2941|\n",
      "|  48| 2641|\n",
      "|   5| 6252|\n",
      "|  19| 2207|\n",
      "|  41| 2913|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: List the total count of cases for each WARD\n",
    "crimes.filter(crimes.WARD.isNotNull()).groupBy('WARD').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|WARD|count|\n",
      "+----+-----+\n",
      "|null|    1|\n",
      "|  19| 2207|\n",
      "|  36| 2536|\n",
      "|  39| 2598|\n",
      "|  48| 2641|\n",
      "|  33| 2698|\n",
      "|  47| 2708|\n",
      "|  38| 2738|\n",
      "|  45| 2761|\n",
      "|  50| 2877|\n",
      "|  41| 2913|\n",
      "|  40| 2941|\n",
      "|  22| 3014|\n",
      "|  12| 3036|\n",
      "|  13| 3086|\n",
      "|  14| 3146|\n",
      "|  23| 3155|\n",
      "|  35| 3181|\n",
      "|  11| 3216|\n",
      "|  30| 3249|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: List the total count of cases for each WARD, and sort it (by count) in ascending order\n",
    "crimes.groupBy('WARD').count().sort('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|WARD|count|\n",
      "+----+-----+\n",
      "|  42|18548|\n",
      "|  24|12457|\n",
      "|   2|11483|\n",
      "|  28|11071|\n",
      "|  27|10000|\n",
      "|  17| 8595|\n",
      "|   6| 8427|\n",
      "|  21| 8043|\n",
      "|  20| 7608|\n",
      "|   3| 6860|\n",
      "+----+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Show top 10 (WARD, count) pairs with the most number of cases\n",
    "# To sort in descending order, use the desc() function - .sort(desc(\"count\"))\n",
    "from pyspark.sql.functions import desc\n",
    "crimes.groupBy('WARD').count().sort(desc('count')).show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "| PRIMARY DESCRIPTION|count|\n",
      "+--------------------+-----+\n",
      "|               THEFT|64285|\n",
      "|             BATTERY|49276|\n",
      "|     CRIMINAL DAMAGE|28118|\n",
      "|             ASSAULT|19740|\n",
      "|  DECEPTIVE PRACTICE|17923|\n",
      "|       OTHER OFFENSE|16561|\n",
      "|            BURGLARY|12040|\n",
      "|           NARCOTICS|11664|\n",
      "|             ROBBERY|11080|\n",
      "| MOTOR VEHICLE THEFT|10558|\n",
      "|   CRIMINAL TRESPASS| 6832|\n",
      "|   WEAPONS VIOLATION| 5003|\n",
      "|OFFENSE INVOLVING...| 2247|\n",
      "| CRIM SEXUAL ASSAULT| 1539|\n",
      "|PUBLIC PEACE VIOL...| 1386|\n",
      "+--------------------+-----+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: List top 15 categories (PRIMARY DESCRIPTION) of cases\n",
    "from pyspark.sql.functions import desc\n",
    "crimes.groupBy('PRIMARY DESCRIPTION').count().sort(desc('count')).show(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|LOCATION DESCRIPTION|count|\n",
      "+--------------------+-----+\n",
      "|              STREET|58758|\n",
      "|           RESIDENCE|43732|\n",
      "|           APARTMENT|33277|\n",
      "|            SIDEWALK|20542|\n",
      "|               OTHER|10791|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: List top 5 locations (LOCATION DESCRIPTION) where cases occur\n",
    "from pyspark.sql.functions import desc\n",
    "crimes.groupBy('LOCATION DESCRIPTION').count().sort(desc('count')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save one of the results to disk (choose any format)\n",
    "# Note: if your dataframe ends up being partitioned, you can call `your_df.coalesce(1)` before saving (`df.coalesce(1).write...`)\n",
    "from pyspark.sql.functions import desc\n",
    "top_locations = crimes.groupBy('LOCATION DESCRIPTION').count().sort(desc('count')).limit(5)\n",
    "top_locations.write.csv(\"top_five_crime_locations\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: submit the preceeding task as a spark job\n",
    "# 1. Create a python file named jobs/top_20_crime_locations.py\n",
    "# 2. define spark session object\n",
    "#   - from pyspark.sql import SparkSession\n",
    "#   - spark = SparkSession.builder.appName(\"MyAppName\").getOrCreate()\n",
    "# 3. Copy the code in the preceeding cell into the file \n",
    "# 4. submit the job: ${SPARK_HOME}/bin/spark-submit --master local ./jobs/top_20_crime_locations.py\n",
    "\n",
    "# if you get stuck, you can refer to ./jobs/top_N_crime_locations_solution.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use your creativity - create any other interesting DataFrames or insights into the crimes data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SQL with Spark DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(\"../data/people/names.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM names\")\n",
    "# add .show() to see the resulting dataframe. Example:\n",
    "# df = spark.sql(\"SELECT * FROM names\")\n",
    "# df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM names WHERE height > 170\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_data_eng_bootcamp",
   "language": "python",
   "name": ".venv_data_eng_bootcamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
