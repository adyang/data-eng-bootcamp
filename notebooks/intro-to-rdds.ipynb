{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "- RDD API docs: http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD\n",
    "\n",
    "Rules of thumb:\n",
    "- Hit tab to auto-complete\n",
    "- To see all available methods, place a dot (.) after the RDD (e.g. words.) and hit tab \n",
    "- Use `.collect()` to see the contents of the RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that you're using the virtual environment\n",
    "!which python\n",
    "\n",
    "# you should see: /path/to/data-eng-bootcamp/.venv_data_eng_bootcamp/bin/python\n",
    "# otherwise, stop the pyspark process in your terminal, activate the virtual environment, and run this command again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# like in the pyspark shell, SparkContext is already defined\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. RDD Transformations and Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Working with in-memory data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 Working with numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.map(lambda n: n ** 2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: double each number in the original rdd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: calculate sum of all numbers in the original rdd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: (i) square each number, (ii) filter out odd numbers (i.e. keep only even numbers) and (iii) calculate sum of remaining numbers (answer: 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 Working with strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = sc.parallelize(['hello', 'world', 'goodbye', 'world'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.map(lambda word: (word, 1)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Given the list in the preceeding cell, how would you create a list of (word, count)?\n",
    "# hint: http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.reduceByKey\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sc.parallelize([\"Basics of the Unix Philosophy\", \"The ‘Unix philosophy’ originated with Ken Thompson's early meditations on how to design a small but capable operating system with a clean service interface. It grew as the Unix culture learned things about how to get maximum leverage out of Thompson's design. It absorbed lessons from many sources along the way\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: word count, again! \n",
    "# hint: Highlight the whitespace between this cell and the next cell to see the hint\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='white'>Hint: use flatMap!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus task 1: strip non-alphabetical characters (e.g. ‘Unix and Unix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus task 2: sort word count by frequency in descending order\n",
    "# hint: http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.sortBy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Creating a RDD by reading from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Word count on a text file!\n",
    "# Print the top 15 most frequent (word, count) pairs to the screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_absolute_path_of(relative_filepath):\n",
    "    import os\n",
    "    project_dir_name = 'twsg-data-eng-bootcamp'\n",
    "    project_root_dir = os.getcwd().split(project_dir_name)[0] + project_dir_name\n",
    "    return \"{}/{}\".format(project_root_dir, relative_filepath)\n",
    "\n",
    "# unfortunate hackiness to make sure we can get absolute path of the data, no matter where we execute this code in this repo \n",
    "text_file_path = get_absolute_path_of(\"data/word_count/unix-philosophy-basics.txt\")\n",
    "print(\"path to text file - pass this to sc.textFile():\")\n",
    "print(text_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: submit the preceeding task as a spark job\n",
    "# 1. Create a python file named ./jobs/unix_philosophy_word_count.py\n",
    "# 2. define spark session object\n",
    "#   - from pyspark import SparkContext\n",
    "#   - sc = SparkContext(\"local\", \"Unix Word Count\")\n",
    "# 3. Copy your solution code into the file\n",
    "# 4. submit the job: ${SPARK_HOME}/bin/spark-submit --master local ./jobs/unix_philosophy_word_count.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the most top 15 most common words in this file?\n",
    "\n",
    "Highlight the section below to see the answer! vvv\n",
    "\n",
    "<font color='white'>\n",
    "[('', 226),\n",
    " ('the', 214),\n",
    " ('to', 185),\n",
    " ('of', 161),\n",
    " ('and', 133),\n",
    " ('is', 109),\n",
    " ('a', 99),\n",
    " ('in', 79),\n",
    " ('it', 65),\n",
    " ('that', 64),\n",
    " ('be', 58),\n",
    " ('for', 53),\n",
    " ('you', 50),\n",
    " ('Rule', 46),\n",
    " ('programs', 43)]\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_data_eng_bootcamp",
   "language": "python",
   "name": ".venv_data_eng_bootcamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
